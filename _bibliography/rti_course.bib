---
---
References
==========

@book{braitenberg1986vehicles,
  title={Vehicles: Experiments in synthetic psychology},
  author={Braitenberg, Valentino},
  year={1986},
  publisher={MIT press}
}

@article{Marr1982,
abstract = {A computational investigation into the human representation and processing of visual information.},
author = {Marr, D},
doi = {10.1007/s11097-009-9141-7},
isbn = {0716715678},
issn = {15687759},
journal = {Phenomenology and the Cognitive Sciences},
number = {4},
pages = {397},
pmid = {3260955},
title = {{Vision: A Computational Investigation into the Human Representation and Processing of Visual Information}},
url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20{\&}path=ASIN/0716715678},
volume = {8},
year = {1982}
}

@article{Taatgen2010,
abstract = {Cognitive architectures are theories of cognition that try to capture the essential representations and mechanisms that underlie cognition. Research in cognitive architectures has gradually moved from a focus on the functional capabilities of architectures to the ability to model the details of human behavior, and, more recently, brain activity. Although there are many different architectures, they share many identical or similar mechanisms, permitting possible future convergence. In judging the quality of a particular cognitive model, it is pertinent to not just judge its fit to the experimental data but also its simplicity and ability to make predictions.},
author = {Taatgen, Niels and Anderson, John R.},
doi = {10.1111/j.1756-8765.2009.01063.x},
isbn = {1756-8765},
issn = {17568757},
journal = {Topics in Cognitive Science},
keywords = {Cognitive architectures,Cognitive modeling},
number = {4},
pages = {693--704},
title = {{The Past, Present, and Future of Cognitive Architectures}},
volume = {2},
year = {2010}
}

@book{Newell1990,
author = {Newell, Allen},
publisher = {Harvard University Press},
title = {{Unified theories of cognition}},
year = {1990}
}

@misc{Newell1959,
abstract = {Describes a program for general problem solving. Describes prototype program's main characteristics and assesses its capabilities in problem solving.},
author = {Newell, a. and Shaw, J. C. and Simon, H. a.},
booktitle = {IFIP Congress},
doi = {10.1038/224923a0},
file = {:home/clement/work/SPECS/readings/cog{\_}arch/P-1584{\_}Report{\_}On{\_}A{\_}General{\_}Problem-Solving{\_}Program{\_}Feb59.pdf:pdf},
issn = {00280836},
number = {5222},
pages = {256--264},
title = {{Report on a general problem-solving program}},
url = {https://www.u-picardie.fr/{~}furst/docs/Newell{\_}Simon{\_}General{\_}Problem{\_}Solving{\_}1959.pdf},
volume = {224},
year = {1959}
}

@article{Anderson2004,
abstract = {Adaptive control of thought-rational (ACT-R; J. R. Anderson {\&} C. Lebiere, 1998) has evolved into a theory that consists of multiple modules but also explains how these modules are integrated to produce coherent cognition. The perceptual-motor modules, the goal module, and the declarative memory module are presented as examples of specialized systems in ACT-R. These modules are associated with distinct cortical regions. These modules place chunks in buffers where they can be detected by a production system that responds to patterns of information in the buffers. At any point in time, a single production rule is selected to respond to the current pattern. Subsymbolic processes serve to guide the selection of rules to fire as well as the internal operations of some modules. Much of learning involves tuning of these subsymbolic processes. A number of simple and complex empirical examples are described to illustrate how these modules function singly and in concert.},
author = {Anderson, John R and Bothell, Daniel and Byrne, Michael D and Douglass, Scott and Lebiere, Christian and Qin, Yulin},
doi = {10.1037/0033-295X.111.4.1036},
file = {:home/clement/work/SPECS/writings/csn{\_}roadmap/bib/anderson2004anintegratedtheoryofthemind.pdf:pdf},
isbn = {ISSN{\~{}}{\~{}}2004-1901},
issn = {0033-295X},
journal = {Psychological review},
number = {4},
pages = {1036--1060},
pmid = {15482072},
title = {{An integrated theory of the mind.}},
volume = {111},
year = {2004}
}


@article{wilson2013,
abstract = {The most exciting hypothesis in cognitive science right now is the theory that cognition is embodied. Like all good ideas in cognitive science, however, embodiment immediately came to mean six different things. The most common definitions involve the straight-forward claim that "states of the body modify states of the mind." However, the implications of embodiment are actually much more radical than this. If cognition can span the brain, body, and the environment, then the "states of mind" of disembodied cognitive science won't exist to be modified. Cognition will instead be an extended system assembled from a broad array of resources. Taking embodiment seriously therefore requires both new methods and theory. Here we outline four key steps that research programs should follow in order to fully engage with the implications of embodiment. The first step is to conduct a task analysis, which characterizes from a first person perspective the specific task that a perceiving-acting cognitive agent is faced with. The second step is to identify the task-relevant resources the agent has access to in order to solve the task. These resources can span brain, body, and environment. The third step is to identify how the agent can assemble these resources into a system capable of solving the problem at hand. The last step is to test the agent's performance to confirm that agent is actually using the solution identified in step 3. We explore these steps in more detail with reference to two useful examples (the outfielder problem and the A-not-B error), and introduce how to apply this analysis to the thorny question of language use. Embodied cognition is more than we think it is, and we have the tools we need to realize its full potential.},
author = {Wilson, Andrew D and Golonka, Sabrina},
doi = {10.3389/fpsyg.2013.00058},
file = {:home/clement/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wilson, Golonka - 2013 - Embodied Cognition is Not What you Think it is.pdf:pdf},
isbn = {1664-1078 (Electronic)},
issn = {1664-1078},
journal = {Frontiers in psychology},
keywords = {a-not-b,dynamical systems,embodied cognition,outfielder problem,replacement,replacement hypothesis,robotics},
number = {February},
pages = {58},
pmid = {23408669},
title = {{Embodied Cognition is Not What you Think it is.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3569617{\%}7B{\&}{\%}7Dtool=pmcentrez{\%}7B{\&}{\%}7Drendertype=abstract},
volume = {4},
year = {2013}
}

@book{oregan2011red,
  title={Why red doesn't sound like a bell: Understanding the feel of consciousness},
  author={O'Regan, J Kevin},
  year={2011},
  publisher={Oxford University Press}
}

@misc{brooks1991,
abstract = {Artificial intelligence research has foundered on the issue of representation.$\backslash$nWhen intelligence is approached in an incremental manner, with strict$\backslash$nreliance on interfacing to the real world through perception and$\backslash$naction, reliance on representation disappears. In this paper we outline$\backslash$nour approach to incrementally building complete intelligent Creatures.$\backslash$nThe fundamental decomposition of the intelligent system is not into$\backslash$nindependent information processing units which must interface with$\backslash$neach other via representations. Instead, the intelligent system is$\backslash$n$\backslash$ndecomposed into independent and parallel activity producers which$\backslash$nall interface directly to the world through perception and action,$\backslash$nrather than interface to each other particularly much. The notions$\backslash$nof central and peripheral systems evaporateeverything is both central$\backslash$nand peripheral. Based on these principles we have built a very successful$\backslash$nseries of mobile robots which operate without supervision as Creatures$\backslash$nin standard office environments.},
author = {Brooks, Rodney A.},
booktitle = {Artificial Intelligence},
doi = {10.1016/0004-3702(91)90053-M},
isbn = {0004-3702},
issn = {00043702},
number = {1-3},
pages = {139--159},
pmid = {14599324},
title = {{Intelligence without representation}},
volume = {47},
year = {1991}
}

@article{Harnad1990,
abstract = {There has been much discussion recently about the scope and limits of purely symbolic models of the mind and about the proper role of connectionism in cognitive modeling. This paper describes the "symbol grounding problem": How can the semantic interpretation of a formal symbol system be made intrinsic to the system, rather than just parasitic on the meanings in our heads? How can the meanings of the meaningless symbol tokens, manipulated solely on the basis of their (arbitrary) shapes, be grounded in anything but other meaningless symbols? The problem is analogous to trying to learn Chinese from a Chinese/Chinese dictionary alone. A candidate solution is sketched: Symbolic representations must be grounded bottom-up in nonsymbolic representations of two kinds: (1) "iconic representations" , which are analogs of the proximal sensory projections of distal objects and events, and (2) "categorical representations" , which are learned and innate feature-detectors that pick out the invariant features of object and event categories from their sensory projections. Elementary symbols are the names of these object and event categories, assigned on the basis of their (nonsymbolic) categorical representations. Higher-order (3) "symbolic representations" , grounded in these elementary symbols, consist of symbol strings describing category membership relations (e.g., "An X is a Y that is Z"). Connectionism is one natural candidate for the mechanism that learns the invariant features underlying categorical representations, thereby connecting names to the proximal projections of the distal objects they stand for. In this way connectionism can be seen as a complementary component in a hybrid nonsymbolic/symbolic model of the mind, rather than a rival to purely symbolic modeling. Such a hybrid model would not have an autonomous symbolic "module," however; the symbolic functions would emerge as an intrinsically "dedicated" symbol system as a consequence of the bottom-up grounding of categories' names in their sensory representations. Symbol manipulation would be governed not just by the arbitrary shapes of the symbol tokens, but by the nonarbitrary shapes of the icons and category invariants in which they are grounded.},
archivePrefix = {arXiv},
arxivId = {cs/9906002},
author = {Harnad, Stevan},
doi = {10.1016/0167-2789(90)90087-6},
eprint = {9906002},
isbn = {0167-2789},
issn = {01672789},
journal = {Physica D},
pages = {335--346},
primaryClass = {cs},
title = {{The Symbol Grounding Problem}},
url = {http://eprints.soton.ac.uk/258175/1/sgproblem1.html},
volume = {42},
year = {1990}
}
